---
title: "Geocoding"
output: html_document
---

```{r setup, include=FALSE}

library(ggmap)
library(stringr)
library(tidyr)
library(dplyr)
library(purrr)

# Long/Lat (lowerleft) Long/Lat (upper right)
HoustonBoundary <- c(-95.789963, 29.518566, -95.005814, 30.117875)
gmap = get_map(location=c(-95.4142, 29.7907), source="google",zoom=12)

googleproj4 <- "+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext  +no_defs"
googlecrs <- "4326"

testgeocode <- function(x){
              if(length(x$results)==0){
                print(paste("--->", x$status))
              }
}

knitr::opts_chunk$set(echo = TRUE)
```

Build a new data frame with only addresses, delete incomplete records, and
join with last GeoTable so we don't go off and repeat work that has already
been done.


```{r Build a clean input for google geocode, eval=FALSE}
# then clear up to only unique values and split each record in two, one for each
# end of the block. Output will be a datafile of keys and addresses.

df = readRDS("~/Dropbox/CrimeStats/District10hCleanData.rds")
geotable <- readRDS("~/Dropbox/CrimeStats/GeoTable.rds")

#   Build a new dataframe with addresses in it
workingset <- data.frame(paste(df$Block_Range,df$Street,", Houston, TX"), stringsAsFactors = FALSE)
colnames(workingset)[1] = "Address"

workingset$Block_Range <- df$Block_Range

workingset <- unique(workingset) # filter down to unique addresses
#   kill off NA's
workingset <- as.data.frame(workingset[!grepl("9 NA ,|UNK NA", workingset$Address),])

# split out beginning and ending block addresses and street name
workingset[,3] = str_extract(workingset$Address,"^\\d+")
workingset[,4] = str_extract(workingset$Address,"\\d+ ")
workingset[,5] = str_extract(workingset$Address," .+$")
colnames(workingset)[3] = "Add1"
colnames(workingset)[4] = "Add2"
colnames(workingset)[5] = "Street"

# delete records that are incomplete
workingset <- workingset[complete.cases(workingset),]

# match with geotable to use lat long values that are already known
workingset <- left_join(workingset, geotable, by="Address")
workingset <- select(workingset, Address, Add1, Add2, Street.x, Longitude, Latitude)
colnames(workingset)[4]="Street"
# toss rows that have lat long, as we don't need to worry about them.
workingset <- workingset %>% filter(is.na(Longitude)|is.na(Latitude))

```

Actually go get the lat long values from Google, 2400 per day.
When done, redo for those that were skipped or failed, and redo
some that are wierd - sometimes second time works.
Delete any coordinates that land outside the city box, do some 
cleanup, average the block range values, unless there is only
on lat/long set, in which case use it.
Finally save the new GeoTable.


```{r set up}

#   Empty dataframe for accepting lat long values
latlongs <- data.frame(types=character(),
                 Latitude=numeric(), 
                 Longitude=numeric(), 
                 type=character(),
                 StreetName=character(),
                 LocType=character(),
                 stringsAsFactors=FALSE) 

#   Function for pulling fields out of nested lists returned by geocode
getfields <- function(x){
              if(! is.na(x) && length(x$results)>0)  {data.frame(
              Latitude=as.numeric(x$results[[1]]$geometry$location$lat),
              Longitude=as.numeric(x$results[[1]]$geometry$location$lng),
              types=x$results[[1]]$types[1],
              StreetName=x$results[[1]]$formatted_address,
              LocType=x$results[[1]]$geometry$location_type,
              stringsAsFactors = FALSE)
              } else if (exists("x$status") && x["status"]=="ZERO_RESULTS"){
                data.frame(types="ZERO_RESULTS",Latitude=NA,Longitude=NA, StreetName=NA,LocType=NA,stringsAsFactors = FALSE)
              } else{
                data.frame(types=NA,Latitude=NA,Longitude=NA, StreetName=NA,LocType=NA,stringsAsFactors = FALSE)
              }
}
#   initialize workingset first time through with new columns
workingset$lon1 <- NA
workingset$lat1 <- NA
workingset$lon2 <- NA
workingset$lat2 <- NA
workingset$type <- NA
workingset$StreetName <- NA
workingset$LocType <- NA
workingset$type2 <- NA
workingset$StreetName2 <- NA
workingset$LocType2 <- NA

```

Work on ADDR1 iteratively until done

```{r get lat longs from google}
#####################################################
#   Iterate on ADDR1 until exhausted
#####################################################
geocodeQueryCheck()
mask1 <- is.na(workingset$lon1) | is.na(workingset$lat1)& !(workingset$type == "ZERO_RESULTS" & !is.na(workingset$LocType))

sum(mask1)
limit <- min(geocodeQueryCheck(), sum(mask1))
# run geocode for each record up to the daily limit, and then average the lat/long
# values from each end of the block to get a true block center value.

Addresses <- paste(workingset$Add1[mask1][1:limit], workingset$Street[mask1][1:limit])
AllLatLong <- geocode(Addresses, output="all") # geocode addresses

latlongs <- map_df(AllLatLong, getfields) # extract desired fields

workingset$lon1[mask1][1:limit] = latlongs$Longitude
workingset$lat1[mask1][1:limit] = latlongs$Latitude
workingset$type[mask1][1:limit] = latlongs$types
workingset$StreetName[mask1][1:limit] = latlongs$StreetName
workingset$LocType[mask1][1:limit] = latlongs$LocType

map_df(AllLatLong, testgeocode)

##################  lather, rinse, repeat
```

Work on ADDR2 iteratively until done

```{r get lat longs from google}
#####################################################
#   Iterate on ADDR2 until exhausted
#####################################################
geocodeQueryCheck()
mask1 <- is.na(workingset$lon2) | is.na(workingset$lat2)& !(workingset$type == "ZERO_RESULTS" & !is.na(workingset$LocType))

sum(mask1)
limit <- min(geocodeQueryCheck(), sum(mask1))
# run geocode for each record up to the daily limit, and then average the lat/long
# values from each end of the block to get a true block center value.

Addresses <- paste(workingset$Add2[mask1][1:limit], workingset$Street[mask1][1:limit])
AllLatLong <- geocode(Addresses, output="all") # geocode addresses

latlongs <- map_df(AllLatLong, getfields) # extract desired fields

workingset$lon2[mask1][1:limit] = latlongs$Longitude
workingset$lat2[mask1][1:limit] = latlongs$Latitude
workingset$type2[mask1][1:limit] = latlongs$types
workingset$StreetName2[mask1][1:limit] = latlongs$StreetName
workingset$LocType2[mask1][1:limit] = latlongs$LocType

map_df(AllLatLong, testgeocode)

sum(is.na(workingset$lat1)&is.na(workingset$Latitude))
sum(is.na(workingset$lon1)&is.na(workingset$Longitude))
sum(is.na(workingset$lat2)&is.na(workingset$Latitude))
sum(is.na(workingset$lon2)&is.na(workingset$Longitude))
##################  lather, rinse, repeat
```

Clean up coordinates. Check lat-long within bounding box,
look at distance between ADD1 and ADD2, and check input
street name against output street name


```{r Cleanup}

keepworking <- workingset # save just in case
#   set any coordinate outside the box to NA

outside <- (workingset$lon1<HoustonBoundary[1] | workingset$lon1>HoustonBoundary[3]) & !is.na(workingset$lon1)
sum(outside)
workingset$lon1[outside] <- NA
workingset$lat1[outside] <- NA

outside <- (workingset$lon2<HoustonBoundary[1] | workingset$lon2>HoustonBoundary[3]) & !is.na(workingset$lon2)
sum(outside)
workingset$lat2[outside] <- NA
workingset$lon2[outside] <- NA

outside <- (workingset$lat1<HoustonBoundary[2] | workingset$lat1>HoustonBoundary[4]) & !is.na(workingset$lat1)
sum(outside)
workingset$lat1[outside] <- NA
workingset$lon1[outside] <- NA

outside <- (workingset$lat2<HoustonBoundary[2] | workingset$lat2>HoustonBoundary[4]) & !is.na(workingset$lat2)
sum(outside)
workingset$lat2[outside] <- NA
workingset$lon2[outside] <- NA
  
#   Check input street names against output

getstreet <- function(x){
  a <- str_replace(strsplit(x[4]," ,")[[1]][1],"\\d* ","") # get everything before ","
  a[[1]][length(a[[1]])] # take last item in that field
}
#   Pull out names given to google
a <- as.data.frame(apply(workingset,1,getstreet))
names(a) <- "Street"

#  Compare names with names google supplied 
problemchildren <- data.frame(child=character(), stringsAsFactors = FALSE)
for (i in 1:length(a$Street)){
  if (!grepl(a$Street[i], workingset$StreetName[i], ignore.case = TRUE)&!is.na(workingset$StreetName[i])) {
    tempdf <- data.frame(child=paste(i,a$Street[i], workingset$StreetName[i], sep=" : ") )
    problemchildren <- rbind(problemchildren, tempdf)
  }
}

#   null out lat/lon where streets don't match

NullOut <- c( 40, 43, 271, 274, 443, 444, 502, 503, 799, 1752, 1976, 2327, 3971, 3974, 4250, 4253, 4266, 4269, 4312, 4315, 4383, 4384, 4773, 4774, 4852, 4855, 5256, 5257, 5718, 5721, 5759, 5880, 5883, 5893, 6119, 6260, 6287, 6393, 6396
)

for (i in NullOut) {workingset$lat1[i] <- NA
                    workingset$lon1[i] <- NA
                    }

#  Compare names with names google supplied 
problemchildren <- data.frame(child=character(), stringsAsFactors = FALSE)
for (i in 1:length(a$Street)){
  if (!grepl(a$Street[i], workingset$StreetName2[i], ignore.case = TRUE)&!is.na(workingset$StreetName2[i])) {
    tempdf <- data.frame(child=paste(i,a$Street[i], workingset$StreetName2[i], sep=" : ") )
    problemchildren <- rbind(problemchildren, tempdf)
  }
}
NullOut <- c(61, 443, 444, 799, 802, 861, 862, 864, 867, 914, 917, 937, 940, 971, 978, 991, 992, 1003, 1034, 1037, 1042, 1047, 1050, 1055, 1056, 1112, 1113, 1117, 1140, 1185, 1188 
)
for (i in NullOut) {workingset$lat2[i] <- NA
                    workingset$lon2[i] <- NA
                    }

###   some lat/longs are bogus. Find them 
#   If the distance between latlong1 and 2 > 5x the median, flag
distance <- sqrt((workingset$lat2- workingset$lat1)**2 + (workingset$lon2- workingset$lon1)**2)* 69 # approximately in miles
distance <- as.data.frame(distance)
meddist <- 5*median(distance$distance, na.rm = TRUE)
distance[is.na(distance)] <- 0
filter(distance, distance>0.01&distance<5*meddist) %>%
 ggplot() +
 geom_histogram(aes(x=distance),binwidth = 0.01) +
  xlab("miles")

bogus <- distance>meddist

problemchildren <- workingset[bogus,]
problemchildren <- problemchildren %>%
  select(Address, lon1, lat1, lon2, lat2, StreetName, StreetName2) %>%
  mutate(distance=sqrt((lat2- lat1)**2 + (lon2- lon1)**2)* 69)

#   null out bogus lat lons

workingset$lat1[bogus] <- NA
workingset$lon1[bogus] <- NA
workingset$lat2[bogus] <- NA
workingset$lon2[bogus] <- NA
#   Average lats and longs to get block center coordinates

keepworking = workingset
workingset$Longitude <- rowMeans(subset(workingset, select=c(lon1, lon2)), na.rm = TRUE) 
workingset$Latitude <- rowMeans(subset(workingset, select=c(lat1, lat2)), na.rm = TRUE) 

#   create columns for final product to save

getblk <- function(x){return(strsplit(x["Address"]," ", fixed = TRUE)[[1]][1])}
blks <- as.data.frame(apply(workingset,1,getblk), stringsAsFactors = FALSE)
colnames(blks) <- "Block_Range"
workingset <- cbind(workingset, blks, stringsAsFactors=FALSE)

newGeotable <- workingset %>% select(Address, Street, Block_Range, Longitude, Latitude, StreetName)
names(newGeotable) <- c("Address", "Street", "Block_Range","Longitude", "Latitude", "GoogleName")

#   Test to make sure no duplicates being created

a <- bind_rows(geotable, newGeotable)
dupd <- duplicated(a$Address) | duplicated(a$Address, fromLast = TRUE)
dups <- a[dupd,]

#   Append to old geotable
newGeotable <- bind_rows(geotable, newGeotable)

#   Save
saveRDS(newGeotable, "~/Dropbox/CrimeStats/GeoTable.rds")

```



